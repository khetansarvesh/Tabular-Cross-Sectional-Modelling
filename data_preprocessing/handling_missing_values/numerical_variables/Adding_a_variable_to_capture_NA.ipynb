{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"toc":{"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false},"colab":{"provenance":[],"collapsed_sections":["iDnqvpWaXu22","tqqnZhdZXu2-","HHYQo7B2Xu3E","WMYQ3s61Xu3x"]}},"cells":[{"cell_type":"code","metadata":{"id":"fMYLfA0jXu2T"},"source":["import pandas as pd\n","import numpy as np\n","\n","# for regression problems\n","from sklearn.linear_model import LinearRegression, Ridge\n","\n","# for classification\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","\n","# to split and standarize the datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# to evaluate regression models\n","from sklearn.metrics import mean_squared_error\n","\n","# to evaluate classification models\n","from sklearn.metrics import roc_auc_score\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zS5bGP1jXu2a","outputId":"3a0ecc63-5763-4917-dfc1-08dac62f7f51"},"source":["# load the Titanic Dataset with a few variables for demonstration\n","\n","data = pd.read_csv('titanic.csv', usecols = ['Age', 'Fare','Survived'])\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Age</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>7.2500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>38.0</td>\n","      <td>71.2833</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>26.0</td>\n","      <td>7.9250</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>53.1000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>8.0500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived   Age     Fare\n","0         0  22.0   7.2500\n","1         1  38.0  71.2833\n","2         1  26.0   7.9250\n","3         1  35.0  53.1000\n","4         0  35.0   8.0500"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"5FOf31IDXu2f","outputId":"00ef3827-35a5-4d4f-87c8-a3007c485ac8"},"source":["# let's look at the percentage of NA\n","data.isnull().mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Survived    0.000000\n","Age         0.198653\n","Fare        0.000000\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"EInNKfU3Xu2k","outputId":"62c09d54-e0f5-4266-f8ae-86e74b1c811f"},"source":["# let's separate into training and testing set\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, data.Survived, test_size=0.3,\n","                                                    random_state=0)\n","X_train.shape, X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((623, 3), (268, 3))"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"L6O7NBO_Xu2p","outputId":"8b430bda-2a12-4f24-dfd7-e0bde3c77fbd"},"source":["# create variable indicating missingness\n","\n","X_train['Age_NA'] = np.where(X_train['Age'].isnull(), 1, 0)\n","X_test['Age_NA'] = np.where(X_test['Age'].isnull(), 1, 0)\n","\n","X_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Age</th>\n","      <th>Fare</th>\n","      <th>Age_NA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>857</th>\n","      <td>1</td>\n","      <td>51.0</td>\n","      <td>26.5500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>1</td>\n","      <td>49.0</td>\n","      <td>76.7292</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>46.9000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>0</td>\n","      <td>54.0</td>\n","      <td>77.2875</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>578</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>14.4583</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Survived   Age     Fare  Age_NA\n","857         1  51.0  26.5500       0\n","52          1  49.0  76.7292       0\n","386         0   1.0  46.9000       0\n","124         0  54.0  77.2875       0\n","578         0   NaN  14.4583       1"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"ZIt7EK1pXu2u","outputId":"760190dd-7304-49fa-e539-f84253fd8f82"},"source":["# we can see that mean and median are similar. So I will replace with the median\n","X_train.Age.mean(), X_train.Age.median(),"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(29.915338645418327, 29.0)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"UvCQSjNoXu2z","outputId":"99c486e7-c649-409a-adfa-e54249c54da6"},"source":["# let's replace the NA with the median value in the training set\n","X_train['Age'].fillna(X_train.Age.median(), inplace=True)\n","X_test['Age'].fillna(X_train.Age.median(), inplace=True)\n","\n","X_train.head(20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Age</th>\n","      <th>Fare</th>\n","      <th>Age_NA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>857</th>\n","      <td>1</td>\n","      <td>51.0</td>\n","      <td>26.5500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>1</td>\n","      <td>49.0</td>\n","      <td>76.7292</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>46.9000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>0</td>\n","      <td>54.0</td>\n","      <td>77.2875</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>578</th>\n","      <td>0</td>\n","      <td>29.0</td>\n","      <td>14.4583</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>549</th>\n","      <td>1</td>\n","      <td>8.0</td>\n","      <td>36.7500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>0</td>\n","      <td>24.0</td>\n","      <td>247.5208</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>20.0</td>\n","      <td>8.0500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>0</td>\n","      <td>30.0</td>\n","      <td>8.0500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>1</td>\n","      <td>24.0</td>\n","      <td>7.1417</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>653</th>\n","      <td>1</td>\n","      <td>29.0</td>\n","      <td>7.8292</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>235</th>\n","      <td>0</td>\n","      <td>29.0</td>\n","      <td>7.5500</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>785</th>\n","      <td>0</td>\n","      <td>25.0</td>\n","      <td>7.2500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>241</th>\n","      <td>1</td>\n","      <td>29.0</td>\n","      <td>15.5000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>351</th>\n","      <td>0</td>\n","      <td>29.0</td>\n","      <td>35.0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>862</th>\n","      <td>1</td>\n","      <td>48.0</td>\n","      <td>25.9292</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>851</th>\n","      <td>0</td>\n","      <td>74.0</td>\n","      <td>7.7750</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>753</th>\n","      <td>0</td>\n","      <td>23.0</td>\n","      <td>7.8958</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>532</th>\n","      <td>0</td>\n","      <td>17.0</td>\n","      <td>7.2292</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>485</th>\n","      <td>0</td>\n","      <td>29.0</td>\n","      <td>25.4667</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Survived   Age      Fare  Age_NA\n","857         1  51.0   26.5500       0\n","52          1  49.0   76.7292       0\n","386         0   1.0   46.9000       0\n","124         0  54.0   77.2875       0\n","578         0  29.0   14.4583       1\n","549         1   8.0   36.7500       0\n","118         0  24.0  247.5208       0\n","12          0  20.0    8.0500       0\n","157         0  30.0    8.0500       0\n","127         1  24.0    7.1417       0\n","653         1  29.0    7.8292       1\n","235         0  29.0    7.5500       1\n","785         0  25.0    7.2500       0\n","241         1  29.0   15.5000       1\n","351         0  29.0   35.0000       1\n","862         1  48.0   25.9292       0\n","851         0  74.0    7.7750       0\n","753         0  23.0    7.8958       0\n","532         0  17.0    7.2292       0\n","485         0  29.0   25.4667       1"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"iDnqvpWaXu22"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"Lw2MhaYdXu22"},"source":["scaler = StandardScaler()\n","X_train = pd.DataFrame(scaler.fit_transform(X_train))\n","X_test = pd.DataFrame(scaler.transform(X_test))\n","\n","X_train.columns = ['Survived','Age','Fare','Age_NA']\n","X_test.columns = ['Survived','Age','Fare','Age_NA']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwbZ2h84Xu27","outputId":"4838614f-8d42-438f-f8fa-fe116f1e2c46"},"source":["# we compare the models built using Age filled with median, vs Age filled with median + additional\n","# variable indicating missingness\n","\n","logit = LogisticRegression(random_state=44, C=1000) # c big to avoid regularization\n","logit.fit(X_train[['Age','Fare']], y_train)\n","print('Train set')\n","pred = logit.predict_proba(X_train[['Age','Fare']])\n","print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n","print('Test set')\n","pred = logit.predict_proba(X_test[['Age','Fare']])\n","print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n","\n","logit = LogisticRegression(random_state=44, C=1000) # c big to avoid regularization\n","logit.fit(X_train[['Age','Age_NA', 'Fare']], y_train)\n","print('Train set')\n","pred = logit.predict_proba(X_train[['Age','Age_NA', 'Fare']])\n","print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n","print('Test set')\n","pred = logit.predict_proba(X_test[['Age','Age_NA', 'Fare']])\n","print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train set\n","Logistic Regression roc-auc: 0.6794863451985858\n","Test set\n","Logistic Regression roc-auc: 0.7244940476190476\n","Train set\n","Logistic Regression roc-auc: 0.6762705798138868\n","Test set\n","Logistic Regression roc-auc: 0.7167857142857142\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tqqnZhdZXu2-"},"source":["### Support Vector Machine"]},{"cell_type":"code","metadata":{"id":"EMzW3SzEXu2_","outputId":"1c974327-a23e-4a0c-f4f8-f1bac9b281fb"},"source":["# we compare the models built using Age filled with median, vs Age filled with median + additional\n","# variable indicating missingness\n","\n","SVM_model = SVC(random_state=44, probability=True, max_iter=-1, kernel='linear')\n","SVM_model.fit(X_train[['Age', 'Fare']], y_train)\n","print('Train set')\n","pred = SVM_model.predict_proba(X_train[['Age', 'Fare']])\n","print('SVC roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n","print('Test set')\n","pred = SVM_model.predict_proba(X_test[['Age', 'Fare']])\n","print('SCV roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n","\n","# model build using natural distributions\n","\n","SVM_model = SVC(random_state=44, probability=True, max_iter=-1, kernel='linear')\n","SVM_model.fit(X_train[['Age','Age_NA', 'Fare']], y_train)\n","print('Train set')\n","pred = SVM_model.predict_proba(X_train[['Age','Age_NA', 'Fare']])\n","print('SVC roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n","print('Test set')\n","pred = SVM_model.predict_proba(X_test[['Age','Age_NA', 'Fare']])\n","print('SVC roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train set\n","SVC roc-auc: 0.692978460337086\n","Test set\n","SCV roc-auc: 0.7418154761904762\n","Train set\n","SVC roc-auc: 0.6917203531376761\n","Test set\n","SVC roc-auc: 0.7360714285714286\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ST3Yu-RPXu3D"},"source":["In the titanic dataset, including a variable to indicate missingness for Age did not show an improvement in the performance of the logistic regression and barely the support vector machine."]},{"cell_type":"markdown","metadata":{"id":"HHYQo7B2Xu3E"},"source":["### House Sale Dataset"]},{"cell_type":"code","metadata":{"id":"hyNYGHnmXu3E"},"source":["# we are going to train a model on the following variables,\n","\n","cols_to_use = ['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea','WoodDeckSF', 'BsmtUnfSF',\n","               'LotFrontage', 'MasVnrArea', 'GarageYrBlt']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4oRB0mkeXu3J","outputId":"2ec08d24-f68c-43b9-f465-051291d21f76"},"source":["# let's load the House Sale Price dataset\n","\n","data = pd.read_csv('houseprice.csv', usecols=cols_to_use+['SalePrice'])\n","print(data.shape)\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1460, 10)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotFrontage</th>\n","      <th>OverallQual</th>\n","      <th>MasVnrArea</th>\n","      <th>BsmtUnfSF</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>GarageYrBlt</th>\n","      <th>WoodDeckSF</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>65.0</td>\n","      <td>7</td>\n","      <td>196.0</td>\n","      <td>150</td>\n","      <td>856</td>\n","      <td>856</td>\n","      <td>1710</td>\n","      <td>2003.0</td>\n","      <td>0</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>80.0</td>\n","      <td>6</td>\n","      <td>0.0</td>\n","      <td>284</td>\n","      <td>1262</td>\n","      <td>1262</td>\n","      <td>1262</td>\n","      <td>1976.0</td>\n","      <td>298</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>68.0</td>\n","      <td>7</td>\n","      <td>162.0</td>\n","      <td>434</td>\n","      <td>920</td>\n","      <td>920</td>\n","      <td>1786</td>\n","      <td>2001.0</td>\n","      <td>0</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>60.0</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>540</td>\n","      <td>756</td>\n","      <td>961</td>\n","      <td>1717</td>\n","      <td>1998.0</td>\n","      <td>0</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>84.0</td>\n","      <td>8</td>\n","      <td>350.0</td>\n","      <td>490</td>\n","      <td>1145</td>\n","      <td>1145</td>\n","      <td>2198</td>\n","      <td>2000.0</td>\n","      <td>192</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotFrontage  OverallQual  MasVnrArea  BsmtUnfSF  TotalBsmtSF  1stFlrSF  \\\n","0         65.0            7       196.0        150          856       856   \n","1         80.0            6         0.0        284         1262      1262   \n","2         68.0            7       162.0        434          920       920   \n","3         60.0            7         0.0        540          756       961   \n","4         84.0            8       350.0        490         1145      1145   \n","\n","   GrLivArea  GarageYrBlt  WoodDeckSF  SalePrice  \n","0       1710       2003.0           0     208500  \n","1       1262       1976.0         298     181500  \n","2       1786       2001.0           0     223500  \n","3       1717       1998.0           0     140000  \n","4       2198       2000.0         192     250000  "]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"-z0WEiKOXu3L","outputId":"5d4222d3-3f51-4b53-e623-a0e78ccc5629"},"source":["# let's inspect the columns  with missing values\n","data.isnull().mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LotFrontage    0.177397\n","OverallQual    0.000000\n","MasVnrArea     0.005479\n","BsmtUnfSF      0.000000\n","TotalBsmtSF    0.000000\n","1stFlrSF       0.000000\n","GrLivArea      0.000000\n","GarageYrBlt    0.055479\n","WoodDeckSF     0.000000\n","SalePrice      0.000000\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"u5_NdittXu3R","outputId":"f935bd66-bc55-476a-d504-0c477d6d72ae"},"source":["# let's separate into training and testing set\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, data.SalePrice, test_size=0.3,\n","                                                    random_state=0)\n","X_train.shape, X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1022, 10), (438, 10))"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"HLzZJVI7Xu3W"},"source":["We observed that the numerical variables are not normally distributed. In particular, most of them apart from YearBuilt are skewed."]},{"cell_type":"code","metadata":{"id":"ZnL3Eb10Xu3W"},"source":["# let's make a function to replace the NA with median or 0s\n","\n","def impute_na(df, variable, median):\n","    df[variable+'_NA'] = np.where(df[variable].isnull(), 1, 0)\n","    df[variable].fillna(median, inplace=True)\n",""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRRaJvYaXu3Z","outputId":"441bbc6a-662e-45ac-9534-1b903ccc8ee1"},"source":["# let's look at the median of the variables with NA\n","\n","X_train[['LotFrontage', 'MasVnrArea', 'GarageYrBlt']].median()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LotFrontage      69.0\n","MasVnrArea        0.0\n","GarageYrBlt    1979.0\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"V8XK9iICXu3c"},"source":["# let's impute the NA with  the median\n","# remember that we need to impute with the median for the train set, and then propagate to test set\n","\n","median = X_train.LotFrontage.median()\n","impute_na(X_train, 'LotFrontage', median)\n","impute_na(X_test, 'LotFrontage', median)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wwvud3XCXu3f"},"source":["median = X_train.MasVnrArea.median()\n","impute_na(X_train, 'MasVnrArea', median)\n","impute_na(X_test, 'MasVnrArea', median)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OF2WU50vXu3i"},"source":["median = X_train.GarageYrBlt.median()\n","impute_na(X_train, 'GarageYrBlt', median)\n","impute_na(X_test, 'GarageYrBlt', median)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jx3feehuXu3l","outputId":"db072186-7ad8-4b93-e1d8-b3e1a40dd8e2"},"source":["X_train.isnull().mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LotFrontage       0.0\n","OverallQual       0.0\n","MasVnrArea        0.0\n","BsmtUnfSF         0.0\n","TotalBsmtSF       0.0\n","1stFlrSF          0.0\n","GrLivArea         0.0\n","GarageYrBlt       0.0\n","WoodDeckSF        0.0\n","SalePrice         0.0\n","LotFrontage_NA    0.0\n","MasVnrArea_NA     0.0\n","GarageYrBlt_NA    0.0\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"_q9fo0nqXu3o","outputId":"41839b5f-2f46-424d-b3db-86de49685b26"},"source":["# create a list with the untransformed columns\n","cols_to_use_no_na = X_train.columns[:-4]\n","cols_to_use_no_na"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['LotFrontage', 'OverallQual', 'MasVnrArea', 'BsmtUnfSF', 'TotalBsmtSF',\n","       '1stFlrSF', 'GrLivArea', 'GarageYrBlt', 'WoodDeckSF'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"PNCGoquHXu3r","outputId":"26b2b6ec-72bd-4ab1-bfbf-161ca5ca3d82"},"source":["cols_to_use = list(X_train.columns)\n","cols_to_use.remove('SalePrice')\n","cols_to_use"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['LotFrontage',\n"," 'OverallQual',\n"," 'MasVnrArea',\n"," 'BsmtUnfSF',\n"," 'TotalBsmtSF',\n"," '1stFlrSF',\n"," 'GrLivArea',\n"," 'GarageYrBlt',\n"," 'WoodDeckSF',\n"," 'LotFrontage_NA',\n"," 'MasVnrArea_NA',\n"," 'GarageYrBlt_NA']"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"lB7f2kioXu3v"},"source":["# let's standarise the dataset\n","scaler = StandardScaler()\n","X_train_no_na = scaler.fit_transform(X_train[cols_to_use_no_na])\n","X_test_no_na = scaler.transform(X_test[cols_to_use_no_na])\n","\n","scaler = StandardScaler()\n","X_train_all = scaler.fit_transform(X_train[cols_to_use])\n","X_test_all = scaler.transform(X_test[cols_to_use])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WMYQ3s61Xu3x"},"source":["### Linear Regression"]},{"cell_type":"code","metadata":{"id":"ClbMNhdLXu3y","outputId":"48f5e256-d9cd-4bc2-d4e2-77fbc07b1ab2"},"source":["# we compare the models built using Age filled with median, vs Age filled with median + additional\n","# variable indicating missingness\n","\n","linreg = LinearRegression()\n","linreg.fit(X_train_no_na, y_train)\n","print('Train set')\n","pred = linreg.predict(X_train_no_na)\n","print('Linear Regression mse: {}'.format(mean_squared_error(y_train, pred)))\n","print('Test set')\n","pred = linreg.predict(X_test_no_na)\n","print('Linear Regression mse: {}'.format(mean_squared_error(y_test, pred)))\n","print()\n","linreg = LinearRegression()\n","linreg.fit(X_train_all, y_train)\n","print('Train set')\n","pred = linreg.predict(X_train_all)\n","print('Linear Regression mse: {}'.format(mean_squared_error(y_train, pred)))\n","print('Test set')\n","pred = linreg.predict(X_test_all)\n","print('Linear Regression mse: {}'.format(mean_squared_error(y_test, pred)))\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train set\n","Linear Regression mse: 1161895545.483203\n","Test set\n","Linear Regression mse: 2212393764.7463093\n","\n","Train set\n","Linear Regression mse: 1157194541.9444427\n","Test set\n","Linear Regression mse: 2197999822.6527514\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jySHC6dCXu31","outputId":"c119d14a-de99-441c-afbf-755fd810e70e"},"source":["#  what is the difference in price estimated by the 2 models?\n","\n","2212393764-2197999822"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14393942"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"AtoPGqtAXu34"},"source":["Here, when we build a model using the additional variable to capture missingness of data, we observe in the test set that the mse is smaller. This means that the difference between the real value and the estimated value is smaller, and thus our model performs better.\n","\n","There is a difference of ~14 million between the model that replaces with the median and the one that uses median imputation in combination with the additional variables to capture missingness. So even when the difference in mse seems small, when we boil it down to business value, the impact is massive.\n","\n","For a discussion on why the median imputation is not enough in this dataset, refer to lecture \"Replacing NA by mean or median\""]},{"cell_type":"code","metadata":{"id":"W1yZy-iMXu34","outputId":"6be4723b-623d-40f1-e723-af533c173887"},"source":["# we compare the models built using Age filled with median, vs Age filled with median + additional\n","# variable indicating missingness\n","\n","#  Ridge, is a regularised linear regression.\n","\n","linreg = Ridge(random_state=30, max_iter=5, tol=100, alpha=10)\n","linreg.fit(X_train_no_na, y_train)\n","print('Train set')\n","pred = linreg.predict(X_train_no_na)\n","print('Ridge Regression mse: {}'.format(mean_squared_error(y_train, pred)))\n","print('Test set')\n","pred = linreg.predict(X_test_no_na)\n","print('Ridge Regression mse: {}'.format(mean_squared_error(y_test, pred)))\n","print()\n","\n","linreg = Ridge(random_state=30, max_iter=5, tol=100, alpha=10)\n","linreg.fit(X_train_all, y_train)\n","print('Train set')\n","pred = linreg.predict(X_train_all)\n","print('Ridge Regression mse: {}'.format(mean_squared_error(y_train, pred)))\n","print('Test set')\n","pred = linreg.predict(X_test_all)\n","print('Ridge Regression mse: {}'.format(mean_squared_error(y_test, pred)))\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train set\n","Ridge Regression mse: 1162112961.4104362\n","Test set\n","Ridge Regression mse: 2203311969.187996\n","\n","Train set\n","Ridge Regression mse: 1157413427.915226\n","Test set\n","Ridge Regression mse: 2188469437.2202415\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fUYV3hFjXu37"},"source":["We observe the same conclusion when using regularised linear regression."]}]}