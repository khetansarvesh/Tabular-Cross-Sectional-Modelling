# Binomial Classification---From-Scratch
In this project, I have implemented several classification algorithms from scratch i.e. not used any standard libraries like sklearn or tensorflow and created my own library for each algorithm, then I compared the results that we got using my custom lilbrary with the results obtained when we used standard library and see how efficiently I have implemented my own library.

  ## 1. Linear Discriminant Analysis (LDA)
 
  This project teaches us how actually the multiple Fisherâ€™s Linear Discriminant Analysis (FLDA) (also called simply as linear discriminant analysis (LDA)) algorithm is used to solve the classification problem and how 
  it is written in the sklearn library and the indepth mathematical intuition behind this algorithm because i have implemented this algorithm from scratch

  The entire theory for the implementation can be understood by referring to my notes at following link (recommended as must read) : [theory](https://drive.google.com/drive/folders/1iXqW0q5vK3k1nb-agum3JACXigii7xCB?usp=sharing)

  The dataset used can be found at this link : [dataset](https://github.com/khetansarvesh/Tabular-Cross-Sectional-Modelling/blob/main/dataset/dataset_FLD.csv)

  The code for the implementation from scratch can be found at following link (open with google colab) : [Code](https://github.com/khetansarvesh/Tabular-Cross-Sectional-Modelling/blob/main/modelling/classification/Multiple-FLDA/code.ipynb)
  
  Please refer to the pdf above named 'Linear Discriminant Analysis (LDA)' to understand code design and result analysis : [report](https://github.com/khetansarvesh/Tabular-Cross-Sectional-Modelling/blob/main/modelling/classification/Multiple-FLDA/report.pdf)
  
  
  ## 2. Logistic Regression (LR)
  This project teaches us how actually logistic regression algorithm is used to solve classification problems and how it is written in the sklearn library and the indepth mathematical intuition behind this algorithm 
  because I have implemented this algorithm from scratch.

  The entire theory for the implementation of can be understood by referring to my notes at following link (recommended as must read) : [theory](https://drive.google.com/drive/folders/1M9TUIqTUfHXr-YdaDzDNchCqjjTHYZQL?usp=sharing)
  
  The dataset used can be found at this link : [dataset](https://github.com/khetansarvesh/Tabular-Cross-Sectional-Modelling/blob/main/dataset/dataset_LR.csv)

  By reading the theory you might have understood that ultimately the algorithm reduces to solving a convex unconstrained nonlinear optimization problem and we know there are several ways to solve this optimization 
  problem problem so here we will be solving this optimization problem via these methods from scratch:
  1. Gradient Descent
  2. Stochastic Gradient Descent
   
  The code for the implementation from scratch can be found at following link : [Code](https://github.com/khetansarvesh/Tabular-Cross-Sectional-Modelling/blob/main/modelling/classification/Multiple-Logistic-Regression/code.ipynb) 
  
  Please refer to the pdf above named 'Logistic Regression (LR)' to understand code design and result analysis : [Report](https://github.com/khetansarvesh/Tabular-Cross-Sectional-Modelling/blob/main/modelling/classification/Multiple-Logistic-Regression/report.pdf)

  ## 3. Artificial Neural Network (ANN)




  

# Multivariate Classification---From-Scratch

  ## 1. Artificial Neural Network (ANN)
  
  To understand theory go to my notes at following link : https://docs.google.com/document/d/1cJL0vdMGqBDkdYbNuErdre0F0NtuCVn87-3xMsHAWfM/edit?usp=sharing
 
  Dataset can be found at following link : https://drive.google.com/file/d/1WA45oguNvTvWYJgCxRdq6vUdlmM57psl/view?usp=sharing
  
  Please refer to following link for entire code implementation : https://colab.research.google.com/drive/1pfROS2lbTmh0sEC0T8IMyQJiIdsRBcAJ?usp=sharing
  
