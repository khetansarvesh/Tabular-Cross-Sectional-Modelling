{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["brppqfkbk4CY","KxgAuUdIrHj5","iiPb-LnPqQa7","wpvpOzruq_8I","GkJ81p3GUVPM","ZHcL3owPs24z","LMCbroAus5H4"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Without Using Library"],"metadata":{"id":"brppqfkbk4CY"}},{"cell_type":"code","source":["  for i in range(no_of_iterations):\n","\n","    #-----------------------forward propagation/pass : moving from input layer to output layer-----------------------\n","    Z1 = Xp.dot(W1.T) + b1 #1xhidden_units\n","    A1 = sigmoid(Z1) #1xhidden_units\n","    Z2 = A1.dot(W.T) + b #1x10\n","    A2 = sigmoid(Z2) #1x10\n","\n","    #-----------------------backward propagation/pass (BACKPROP) : moving from derivative of error wrt output weights to derivative of error wrt hidden weights-----------------------\n","    '''\n","    it is a big myth that backprop is used to find weights, it is used to find derivatives of loss function wrt weight ~BHANU SIR\n","    '''\n","    db = (-1)*(Yp/A2)*(sigmoid_derivative(Z2)) + ((1-Yp)/(1-A2))*(sigmoid_derivative(Z2)) #1X10\n","    dW = db.T.dot(A1)#10X8 = 10X1 X 1X8\n","    db1 = (db.dot(W))*sigmoid_derivative(Z1)#1X8 = (1X10 X 10X8) X 1X8\n","    dW1 = (db1.T).dot(Xp)# 8X6 = 8X1 X 1X6\n","\n","    #-----------------------weight update rule-----------------------\n","    W = W - (learning_rate)*(dW)\n","    b = b - (learning_rate)*(db)\n","    W1 = W1 - (learning_rate)*(dW1)\n","    b1 = b1 - (learning_rate)*(db1)"],"metadata":{"id":"4NJX1tVpk7r3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SKLearn Library"],"metadata":{"id":"KxgAuUdIrHj5"}},{"cell_type":"code","source":[],"metadata":{"id":"0VdPqG0TrI_X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pytorch Library"],"metadata":{"id":"iiPb-LnPqQa7"}},{"cell_type":"code","metadata":{"id":"jn-YUjPhIPQB"},"source":["import torch\n","import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpvpOzruq_8I"},"source":["## Reading the Data"]},{"cell_type":"code","metadata":{"id":"6YQXDFPAntgm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625892827565,"user_tz":-330,"elapsed":342,"user":{"displayName":"Sarvesh Khetan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYvgp8tsqLQjHL82OfSEL-YYRULs9eO8SLPw2rDg=s64","userId":"17514303311129929608"}},"outputId":"f7befaa6-d141-4a87-a88d-fd10b667e458"},"source":["x = torch.randn(10, 5) # creating sample dataset with just 5 independent features - x1,x2,x3,x4,x5 and 2 rows\n","x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.7291,  0.4404,  0.7578,  0.4639, -2.3318],\n","        [ 0.7860, -1.4743, -0.2078,  2.1465,  0.9656],\n","        [-0.0981, -1.4432, -0.4456,  1.2821,  0.7947],\n","        [-0.6662, -0.1653,  0.9072, -0.2723, -0.7541],\n","        [ 1.1028,  1.0250, -0.0324, -0.8906,  0.1825],\n","        [-0.5247, -0.2951,  1.1351, -0.5000, -0.5514],\n","        [-0.1172,  0.9355,  0.6465,  0.2800, -2.0848],\n","        [ 0.3324, -1.3001,  0.2113, -1.1132, -0.0525],\n","        [-0.3646, -0.5164,  0.6157, -0.1626, -0.5585],\n","        [ 0.6597, -0.4562,  0.2526, -1.0284,  2.6795]])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGYFiaT_vXBn","executionInfo":{"status":"ok","timestamp":1625892934582,"user_tz":-330,"elapsed":331,"user":{"displayName":"Sarvesh Khetan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYvgp8tsqLQjHL82OfSEL-YYRULs9eO8SLPw2rDg=s64","userId":"17514303311129929608"}},"outputId":"ef43a758-1886-46a1-b7ca-95dfb489abdb"},"source":["# Create the y data\n","y = torch.randn(10, 1)\n","y"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.4462],\n","        [-0.5048],\n","        [-0.2460],\n","        [ 0.3775],\n","        [ 0.7790],\n","        [-0.1212],\n","        [ 1.4909],\n","        [-1.2442],\n","        [-0.2524],\n","        [-0.0114]])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"GkJ81p3GUVPM"},"source":["## Defining our Model using Custom Modules\n","\n","Instead of using the predefined modules, we can also build our own by extending the `nn.Module` class.\n","\n","To create a custom module, the first thing we have to do is to extend the `nn.Module`. We can then initialize our parameters in the `__init__` function, starting with a call to the `__init__` function of the super class. All the class attributes we define which are `nn` module objects are treated as parameters, which can be learned during the training. Tensors are not parameters, but they can be turned into parameters if they are wrapped in `nn.Parameter` class.\n","\n","All classes extending `nn.Module` are also expected to implement a `forward(x)` function, where `x` is a tensor. This is the function that is called when a parameter is passed to our module, such as in `model(x)`."]},{"cell_type":"code","metadata":{"id":"J2P7eZiMj32_"},"source":["# creating a two hidden layer FFNN for regression\n","class SarveshANN(nn.Module):\n","\n","  def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n","\n","    #Call to the __init__ function of the super class\n","    super(SarveshANN, self).__init__()\n","\n","    #Bookkeeping: Saving the initialization parameters\n","    self.input_size = input_size\n","    self.hidden1_size = hidden1_size\n","    self.hidden2_size = hidden2_size\n","    self.output_size = output_size\n","\n","    #Defining the model\n","    self.model = nn.Sequential(\n","        nn.Linear(self.input_size, self.hidden1_size),\n","        nn.ReLU(),\n","        nn.Linear(self.hidden1_size, self.hidden2_size),\n","        nn.ReLU(),\n","        nn.Linear(self.hidden2_size, self.output_size),\n","        nn.Identity()\n","    )\n","#nn.ReLU(), nn.Sigmoid() and nn.LeakyReLU()\n","  def forward(self, x):\n","    output = self.model(x)\n","    return output\n","\n","#Here is an alternative way to define the same class. You can see that we can replace nn.Sequential by defining the individual layers in the __init__ method and connecting the in the forward function.\n","#class MultilayerPerceptron(nn.Module):\n","\n","#  def __init__(self, input_size, hidden_size):\n","    # Call to the __init__ function of the super class\n","#    super(MultilayerPerceptron, self).__init__()\n","\n","    # Bookkeeping: Saving the initialization parameters\n","#    self.input_size = input_size\n","#    self.hidden_size = hidden_size\n","\n","    # Defining of our layers\n","#    self.linear = nn.Linear(self.input_size, self.hidden_size)\n","#    self.relu = nn.ReLU()\n","#    self.linear2 = nn.Linear(self.hidden_size, self.input_size)\n","#    self.sigmoid = nn.Sigmoid()\n","\n","#  def forward(self, x):\n","#    linear = self.linear(x)\n","#    relu = self.relu(linear)\n","#    linear2 = self.linear2(relu)\n","#    output = self.sigmoid(linear2)\n","#    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXi0T0FZbV0y","executionInfo":{"status":"ok","timestamp":1625894463054,"user_tz":-330,"elapsed":363,"user":{"displayName":"Sarvesh Khetan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYvgp8tsqLQjHL82OfSEL-YYRULs9eO8SLPw2rDg=s64","userId":"17514303311129929608"}},"outputId":"1571e8ca-d38c-4a14-a805-86774c8d7291"},"source":["# instantiating the model\n","model = SarveshANN(5,10,5,1) # 5 cause we have 5 features, 10 hidden units in hiddlen layer1, 5 hidden units in hidden layer2 and just 1 output unit\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SarveshANN(\n","  (model): Sequential(\n","    (0): Linear(in_features=5, out_features=10, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=10, out_features=5, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=5, out_features=1, bias=True)\n","    (5): Identity()\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7d23soYIb2WZ","executionInfo":{"status":"ok","timestamp":1625897603873,"user_tz":-330,"elapsed":363,"user":{"displayName":"Sarvesh Khetan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYvgp8tsqLQjHL82OfSEL-YYRULs9eO8SLPw2rDg=s64","userId":"17514303311129929608"}},"outputId":"10f279d8-bace-45a0-fc21-53163ac40516"},"source":["list(model.named_parameters()) #alternative to this is model.parameters() function -> these function gives the initial random parameters the model is taking"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('model.0.weight', Parameter containing:\n","  tensor([[-0.2559,  0.2649, -0.0537, -0.0286,  0.3346],\n","          [-0.0139,  0.4457,  0.3879,  0.4450, -0.3163],\n","          [ 0.2954,  0.3767,  0.4416,  0.1291, -0.0380],\n","          [-0.1830, -0.0354,  0.2354,  0.3366,  0.3842],\n","          [-0.3997, -0.2525, -0.3182,  0.2405,  0.3490],\n","          [-0.3522,  0.0324,  0.1795, -0.0540, -0.0234],\n","          [ 0.3768, -0.0812,  0.3992,  0.3240,  0.4382],\n","          [ 0.2240,  0.3083,  0.1131,  0.2188,  0.1478],\n","          [ 0.1752,  0.2188, -0.0049, -0.3777,  0.4376],\n","          [-0.2581,  0.0958,  0.3011, -0.3008,  0.2002]], requires_grad=True)),\n"," ('model.0.bias', Parameter containing:\n","  tensor([-0.2308,  0.1004, -0.3939,  0.1638, -0.0436, -0.1687, -0.0675,  0.2156,\n","           0.4307, -0.4149], requires_grad=True)),\n"," ('model.2.weight', Parameter containing:\n","  tensor([[-0.2661, -0.0350,  0.3118,  0.0334,  0.0921,  0.0074,  0.2894, -0.0901,\n","            0.0221,  0.2854],\n","          [-0.2084, -0.1682, -0.2330, -0.1889, -0.2143, -0.1303, -0.1252, -0.1246,\n","           -0.3036,  0.0225],\n","          [-0.2381,  0.0817, -0.1722, -0.2472,  0.0660,  0.0480, -0.1902, -0.1604,\n","            0.2971, -0.0143],\n","          [-0.1932,  0.2533, -0.1191,  0.2800,  0.0295, -0.1017,  0.1125,  0.1617,\n","           -0.1691, -0.1046],\n","          [-0.1073,  0.0555, -0.1207,  0.1630,  0.1259,  0.1256,  0.1207, -0.2558,\n","            0.0272,  0.3004]], requires_grad=True)),\n"," ('model.2.bias', Parameter containing:\n","  tensor([-0.1192, -0.2402, -0.2444,  0.1181,  0.3136], requires_grad=True)),\n"," ('model.4.weight', Parameter containing:\n","  tensor([[-0.2047, -0.2851,  0.0763,  0.0863, -0.3460]], requires_grad=True)),\n"," ('model.4.bias', Parameter containing:\n","  tensor([0.1409], requires_grad=True))]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"2oA2XsdsbN8p"},"source":["# Define the optimizer\n","import torch.optim as optim\n","adam = optim.Adam(model.parameters(), lr=1e-1)\n","\n","# Define loss using a predefined loss function\n","loss_function = nn.MSELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZHcL3owPs24z"},"source":["## Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogl6-Ctmuek6","executionInfo":{"status":"ok","timestamp":1625897636214,"user_tz":-330,"elapsed":1171,"user":{"displayName":"Sarvesh Khetan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYvgp8tsqLQjHL82OfSEL-YYRULs9eO8SLPw2rDg=s64","userId":"17514303311129929608"}},"outputId":"b4e904f2-f4f9-44d7-ac1e-3b35aecb8de7"},"source":["# Set the number of epoch, which determines the number of training iterations\n","n_epoch = 10\n","\n","for epoch in range(n_epoch):\n","\n","  #Set the gradients to 0\n","  adam.zero_grad()\n","\n","  #forward propagation\n","  y_pred = model(x)\n","  loss = loss_function(y_pred, y)\n","  print(f\"Epoch {epoch}: traing loss: {loss}\")\n","\n","  #backward propagation to compute the gradients\n","  loss.backward()\n","\n","  #Updating weights - Take a step to optimize the weights\n","  adam.step()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0: traing loss: 0.46382957696914673\n","Epoch 1: traing loss: 0.41810521483421326\n","Epoch 2: traing loss: 0.33339884877204895\n","Epoch 3: traing loss: 0.2539175748825073\n","Epoch 4: traing loss: 0.2533775269985199\n","Epoch 5: traing loss: 0.18649843335151672\n","Epoch 6: traing loss: 0.14389298856258392\n","Epoch 7: traing loss: 0.10955234616994858\n","Epoch 8: traing loss: 0.07010544836521149\n","Epoch 9: traing loss: 0.05134958028793335\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrMJ8AmqeCY-","executionInfo":{"status":"ok","timestamp":1625897658422,"user_tz":-330,"elapsed":360,"user":{"displayName":"Sarvesh Khetan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYvgp8tsqLQjHL82OfSEL-YYRULs9eO8SLPw2rDg=s64","userId":"17514303311129929608"}},"outputId":"95614ecf-51da-4c33-97f2-f8ff7df735f8"},"source":["list(model.parameters()) #parameters learnt after training"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([[ 0.0919,  0.4043,  0.0661, -0.2225,  0.8393],\n","         [-0.1179,  1.2639,  0.4499, -0.0146, -0.3028],\n","         [ 0.0106,  0.4343,  0.2046, -0.2028,  0.1867],\n","         [ 0.0155, -0.7481,  0.4118, -0.2486, -0.0780],\n","         [-0.4846, -0.0452, -0.1402,  0.1874,  0.0923],\n","         [-0.0870, -0.1877, -0.2299, -0.1982,  0.5085],\n","         [-0.1209,  0.0378,  0.5342,  0.3766,  0.1330],\n","         [ 0.1514,  0.9357,  0.3862, -0.3541,  0.0459],\n","         [ 0.4894, -0.0513,  0.0158, -0.6740,  0.0521],\n","         [-0.3115, -0.4785,  0.4461, -0.8579,  0.1322]], requires_grad=True),\n"," Parameter containing:\n"," tensor([-0.0245,  0.6163, -0.4797,  0.7681, -0.2806, -0.5909, -0.3918,  0.6035,\n","          0.5538, -0.0950], requires_grad=True),\n"," Parameter containing:\n"," tensor([[-0.8311, -0.2224,  0.0213, -0.0971, -0.0278,  0.3614,  0.2324, -0.2281,\n","          -0.5414,  0.0140],\n","         [-0.2084, -0.1682, -0.2330, -0.1889, -0.2143, -0.1303, -0.1252, -0.1246,\n","          -0.3036,  0.0225],\n","         [ 0.4306,  0.4888,  0.2491, -0.7698, -0.2877, -0.3806,  0.1916,  0.3423,\n","           0.1539,  0.1210],\n","         [ 0.1611,  0.7229,  0.2285,  0.1945,  0.1785, -0.2081,  0.1291,  0.7284,\n","          -0.4471,  0.1541],\n","         [-0.5596, -0.3539, -0.5394,  0.3081, -0.0510, -0.3657, -0.0052, -0.6545,\n","           0.4191,  0.2309]], requires_grad=True),\n"," Parameter containing:\n"," tensor([-0.3173, -0.2402, -0.5249, -0.0013,  0.6672], requires_grad=True),\n"," Parameter containing:\n"," tensor([[ 0.0526, -0.2851,  0.0453,  0.4148, -0.6113]], requires_grad=True),\n"," Parameter containing:\n"," tensor([-0.0621], requires_grad=True)]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"LMCbroAus5H4"},"source":["## Testing (Prediction)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRqE7P9EtvuS","executionInfo":{"status":"ok","timestamp":1625897669397,"user_tz":-330,"elapsed":360,"user":{"displayName":"Sarvesh Khetan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYvgp8tsqLQjHL82OfSEL-YYRULs9eO8SLPw2rDg=s64","userId":"17514303311129929608"}},"outputId":"20b9999e-f833-4429-d789-67ffc3899b86"},"source":["# See how our model performs on the training data\n","y_pred = model(x)\n","y_pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.9180],\n","        [-0.5824],\n","        [-0.5866],\n","        [ 0.2653],\n","        [ 0.9249],\n","        [ 0.0908],\n","        [ 1.2653],\n","        [-1.4679],\n","        [-0.4246],\n","        [ 0.1427]], grad_fn=<AddmmBackward>)"]},"metadata":{"tags":[]},"execution_count":35}]}]}