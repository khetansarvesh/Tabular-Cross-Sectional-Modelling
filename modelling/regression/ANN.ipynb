{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk4o_LS-jc--"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/Tabular-Cross-Sectional-Modelling/blob/main/modelling/regression/ANN.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "NU_P4sNH-pky"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Processing**"
      ],
      "metadata": {
        "id": "bmDWxZux-IgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(10, 5) # creating sample dataset with just 5 independent features - x1,x2,x3,x4,x5 and 2 rows\n",
        "x"
      ],
      "metadata": {
        "id": "05ekSgoi-Ld-",
        "outputId": "8dd6b52e-b250-416f-87a5-3b5aea427c62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.0891e-01, -4.4023e-01, -8.5300e-01,  9.7805e-01,  5.6652e-02],\n",
              "        [ 5.5181e-01, -1.3340e+00,  1.2891e+00,  9.7943e-01,  1.3466e-01],\n",
              "        [-1.6634e+00, -1.0699e+00, -6.9859e-01, -1.6662e+00,  1.3111e+00],\n",
              "        [-8.4231e-02,  2.6872e-01,  6.7192e-01, -1.3386e+00,  5.7466e-01],\n",
              "        [ 8.7959e-01, -2.2094e+00,  9.3218e-01,  2.1339e-01, -5.6719e-01],\n",
              "        [ 8.3101e-01, -2.9186e-01,  6.3879e-01, -7.6856e-01,  1.0273e+00],\n",
              "        [ 8.6117e-01, -1.3429e+00,  6.0611e-02,  9.8263e-02, -2.2480e-01],\n",
              "        [-5.7655e-01, -1.7413e-01, -4.1327e-01, -7.0351e-01, -1.1554e+00],\n",
              "        [ 3.0365e-02, -2.2806e+00, -6.8178e-01, -9.2001e-01, -9.4490e-01],\n",
              "        [-6.3160e-01, -1.0600e+00, -2.4375e+00,  2.1277e-03, -3.5008e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the y data\n",
        "y = torch.randn(10, 1)\n",
        "y"
      ],
      "metadata": {
        "id": "k1tkYPjW-NBe",
        "outputId": "5c961add-e5f5-48e8-8223-bb1149f9dd5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1520],\n",
              "        [-2.3906],\n",
              "        [ 0.7636],\n",
              "        [-0.4156],\n",
              "        [-0.3451],\n",
              "        [ 0.6496],\n",
              "        [-1.1991],\n",
              "        [ 0.5058],\n",
              "        [-1.3132],\n",
              "        [-0.1949]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelling**"
      ],
      "metadata": {
        "id": "WFknf05o-1NC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brppqfkbk4CY"
      },
      "source": [
        "## **Without Using Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NJX1tVpk7r3"
      },
      "outputs": [],
      "source": [
        "  for i in range(no_of_iterations):\n",
        "\n",
        "    #-----------------------forward propagation/pass : moving from input layer to output layer-----------------------\n",
        "    Z1 = Xp.dot(W1.T) + b1 #1xhidden_units\n",
        "    A1 = sigmoid(Z1) #1xhidden_units\n",
        "    Z2 = A1.dot(W.T) + b #1x10\n",
        "    A2 = sigmoid(Z2) #1x10\n",
        "\n",
        "    #-----------------------backward propagation/pass (BACKPROP) : moving from derivative of error wrt output weights to derivative of error wrt hidden weights-----------------------\n",
        "    '''\n",
        "    it is a big myth that backprop is used to find weights, it is used to find derivatives of loss function wrt weight ~BHANU SIR\n",
        "    '''\n",
        "    db = (-1)*(Yp/A2)*(sigmoid_derivative(Z2)) + ((1-Yp)/(1-A2))*(sigmoid_derivative(Z2)) #1X10\n",
        "    dW = db.T.dot(A1)#10X8 = 10X1 X 1X8\n",
        "    db1 = (db.dot(W))*sigmoid_derivative(Z1)#1X8 = (1X10 X 10X8) X 1X8\n",
        "    dW1 = (db1.T).dot(Xp)# 8X6 = 8X1 X 1X6\n",
        "\n",
        "    #-----------------------weight update rule-----------------------\n",
        "    W = W - (learning_rate)*(dW)\n",
        "    b = b - (learning_rate)*(db)\n",
        "    W1 = W1 - (learning_rate)*(dW1)\n",
        "    b1 = b1 - (learning_rate)*(db1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiPb-LnPqQa7"
      },
      "source": [
        "## **Using Pytorch Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2P7eZiMj32_"
      },
      "outputs": [],
      "source": [
        "# creating a one hidden layer FFNN for regression\n",
        "class SarveshANN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size = 5, hidden_size = 10, output_size = 1): # 5 cause we have 5 features, 10 hidden units in hiddlen layer1 and just 1 output unit\n",
        "    super(SarveshANN, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(input_size, hidden_size),nn.ReLU(),\n",
        "        nn.Linear(hidden_size, output_size),nn.Identity() # nn.Sigmoid() and nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "#Here is an alternative way to define the same class. You can see that we can replace nn.Sequential by defining the individual layers in the __init__ method and connecting the in the forward function.\n",
        "#class MultilayerPerceptron(nn.Module):\n",
        "\n",
        "#  def __init__(self, input_size = 5, hidden_size = 10, output_size = 1):\n",
        "#    super(MultilayerPerceptron, self).__init__()\n",
        "#    self.linear = nn.Linear(input_size, hidden_size)\n",
        "#    self.relu = nn.ReLU()\n",
        "#    self.linear2 = nn.Linear(hidden_size, output_size)\n",
        "#    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "#  def forward(self, x):\n",
        "#    linear = self.linear(x)\n",
        "#    relu = self.relu(linear)\n",
        "#    linear2 = self.linear2(relu)\n",
        "#    output = self.sigmoid(linear2)\n",
        "#    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXi0T0FZbV0y",
        "outputId": "1571e8ca-d38c-4a14-a805-86774c8d7291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SarveshANN(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=5, out_features=1, bias=True)\n",
            "    (5): Identity()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = SarveshANN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d23soYIb2WZ",
        "outputId": "10f279d8-bace-45a0-fc21-53163ac40516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('model.0.weight', Parameter containing:\n",
              "  tensor([[-0.2559,  0.2649, -0.0537, -0.0286,  0.3346],\n",
              "          [-0.0139,  0.4457,  0.3879,  0.4450, -0.3163],\n",
              "          [ 0.2954,  0.3767,  0.4416,  0.1291, -0.0380],\n",
              "          [-0.1830, -0.0354,  0.2354,  0.3366,  0.3842],\n",
              "          [-0.3997, -0.2525, -0.3182,  0.2405,  0.3490],\n",
              "          [-0.3522,  0.0324,  0.1795, -0.0540, -0.0234],\n",
              "          [ 0.3768, -0.0812,  0.3992,  0.3240,  0.4382],\n",
              "          [ 0.2240,  0.3083,  0.1131,  0.2188,  0.1478],\n",
              "          [ 0.1752,  0.2188, -0.0049, -0.3777,  0.4376],\n",
              "          [-0.2581,  0.0958,  0.3011, -0.3008,  0.2002]], requires_grad=True)),\n",
              " ('model.0.bias', Parameter containing:\n",
              "  tensor([-0.2308,  0.1004, -0.3939,  0.1638, -0.0436, -0.1687, -0.0675,  0.2156,\n",
              "           0.4307, -0.4149], requires_grad=True)),\n",
              " ('model.2.weight', Parameter containing:\n",
              "  tensor([[-0.2661, -0.0350,  0.3118,  0.0334,  0.0921,  0.0074,  0.2894, -0.0901,\n",
              "            0.0221,  0.2854],\n",
              "          [-0.2084, -0.1682, -0.2330, -0.1889, -0.2143, -0.1303, -0.1252, -0.1246,\n",
              "           -0.3036,  0.0225],\n",
              "          [-0.2381,  0.0817, -0.1722, -0.2472,  0.0660,  0.0480, -0.1902, -0.1604,\n",
              "            0.2971, -0.0143],\n",
              "          [-0.1932,  0.2533, -0.1191,  0.2800,  0.0295, -0.1017,  0.1125,  0.1617,\n",
              "           -0.1691, -0.1046],\n",
              "          [-0.1073,  0.0555, -0.1207,  0.1630,  0.1259,  0.1256,  0.1207, -0.2558,\n",
              "            0.0272,  0.3004]], requires_grad=True)),\n",
              " ('model.2.bias', Parameter containing:\n",
              "  tensor([-0.1192, -0.2402, -0.2444,  0.1181,  0.3136], requires_grad=True)),\n",
              " ('model.4.weight', Parameter containing:\n",
              "  tensor([[-0.2047, -0.2851,  0.0763,  0.0863, -0.3460]], requires_grad=True)),\n",
              " ('model.4.bias', Parameter containing:\n",
              "  tensor([0.1409], requires_grad=True))]"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.named_parameters()) #alternative to this is model.parameters() function -> these function gives the initial random parameters the model is taking"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "Ema1lnYp_A4L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oA2XsdsbN8p"
      },
      "outputs": [],
      "source": [
        "# Define the optimizer\n",
        "import torch.optim as optim\n",
        "adam = optim.Adam(model.parameters(), lr=1e-1)\n",
        "\n",
        "# Define loss using a predefined loss function\n",
        "loss_function = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogl6-Ctmuek6",
        "outputId": "b4e904f2-f4f9-44d7-ac1e-3b35aecb8de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: traing loss: 0.46382957696914673\n",
            "Epoch 1: traing loss: 0.41810521483421326\n",
            "Epoch 2: traing loss: 0.33339884877204895\n",
            "Epoch 3: traing loss: 0.2539175748825073\n",
            "Epoch 4: traing loss: 0.2533775269985199\n",
            "Epoch 5: traing loss: 0.18649843335151672\n",
            "Epoch 6: traing loss: 0.14389298856258392\n",
            "Epoch 7: traing loss: 0.10955234616994858\n",
            "Epoch 8: traing loss: 0.07010544836521149\n",
            "Epoch 9: traing loss: 0.05134958028793335\n"
          ]
        }
      ],
      "source": [
        "# training for 10 epochs\n",
        "for epoch in range(10):\n",
        "\n",
        "  #Set the gradients to 0\n",
        "  adam.zero_grad()\n",
        "\n",
        "  #forward propagation\n",
        "  y_pred = model(x)\n",
        "  loss = loss_function(y_pred, y)\n",
        "  print(f\"Epoch {epoch}: traing loss: {loss}\")\n",
        "\n",
        "  #backward propagation to compute the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  #Updating weights - Take a step to optimize the weights\n",
        "  adam.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrMJ8AmqeCY-",
        "outputId": "95614ecf-51da-4c33-97f2-f8ff7df735f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0919,  0.4043,  0.0661, -0.2225,  0.8393],\n",
              "         [-0.1179,  1.2639,  0.4499, -0.0146, -0.3028],\n",
              "         [ 0.0106,  0.4343,  0.2046, -0.2028,  0.1867],\n",
              "         [ 0.0155, -0.7481,  0.4118, -0.2486, -0.0780],\n",
              "         [-0.4846, -0.0452, -0.1402,  0.1874,  0.0923],\n",
              "         [-0.0870, -0.1877, -0.2299, -0.1982,  0.5085],\n",
              "         [-0.1209,  0.0378,  0.5342,  0.3766,  0.1330],\n",
              "         [ 0.1514,  0.9357,  0.3862, -0.3541,  0.0459],\n",
              "         [ 0.4894, -0.0513,  0.0158, -0.6740,  0.0521],\n",
              "         [-0.3115, -0.4785,  0.4461, -0.8579,  0.1322]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0245,  0.6163, -0.4797,  0.7681, -0.2806, -0.5909, -0.3918,  0.6035,\n",
              "          0.5538, -0.0950], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.8311, -0.2224,  0.0213, -0.0971, -0.0278,  0.3614,  0.2324, -0.2281,\n",
              "          -0.5414,  0.0140],\n",
              "         [-0.2084, -0.1682, -0.2330, -0.1889, -0.2143, -0.1303, -0.1252, -0.1246,\n",
              "          -0.3036,  0.0225],\n",
              "         [ 0.4306,  0.4888,  0.2491, -0.7698, -0.2877, -0.3806,  0.1916,  0.3423,\n",
              "           0.1539,  0.1210],\n",
              "         [ 0.1611,  0.7229,  0.2285,  0.1945,  0.1785, -0.2081,  0.1291,  0.7284,\n",
              "          -0.4471,  0.1541],\n",
              "         [-0.5596, -0.3539, -0.5394,  0.3081, -0.0510, -0.3657, -0.0052, -0.6545,\n",
              "           0.4191,  0.2309]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3173, -0.2402, -0.5249, -0.0013,  0.6672], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0526, -0.2851,  0.0453,  0.4148, -0.6113]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0621], requires_grad=True)]"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.parameters()) #parameters learnt after training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMCbroAus5H4"
      },
      "source": [
        "# **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRqE7P9EtvuS",
        "outputId": "20b9999e-f833-4429-d789-67ffc3899b86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.9180],\n",
              "        [-0.5824],\n",
              "        [-0.5866],\n",
              "        [ 0.2653],\n",
              "        [ 0.9249],\n",
              "        [ 0.0908],\n",
              "        [ 1.2653],\n",
              "        [-1.4679],\n",
              "        [-0.4246],\n",
              "        [ 0.1427]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See how our model performs on the training data\n",
        "y_pred = model(x)\n",
        "y_pred"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "brppqfkbk4CY",
        "KxgAuUdIrHj5",
        "iiPb-LnPqQa7",
        "wpvpOzruq_8I",
        "GkJ81p3GUVPM",
        "ZHcL3owPs24z",
        "LMCbroAus5H4"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}