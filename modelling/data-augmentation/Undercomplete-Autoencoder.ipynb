{"cells":[{"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/Tabular-Cross-Sectional-Modelling/blob/main/modelling/data-augmentation/Undercomplete-Autoencoder.ipynb)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"H7hAPHtVJFpO"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import tensorflow as tf\n","tf.reset_default_graph() \n","from tensorflow.contrib.layers import fully_connected"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oW2-uIKbTolK"},"outputs":[],"source":["# reading dataset\n","df = pd.read_csv('anonymized_data.csv')\n","\n","# scaling the dataset\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","scaled_data = scaler.fit_transform(df.drop('Label',axis=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkaR4TC0JFpR"},"outputs":[],"source":["# defining network params\n","num_inputs = 30\n","neurons_hid1 = 15\n","neurons_hid2 = 10\n","neurons_hid3 = neurons_hid1\n","num_outputs = num_inputs\n","learning_rate = 0.01\n","num_epochs = 5\n","batch_size = 150\n","\n","# weihts and bias\n","w1 = tf.Variable(initializer([num_inputs, neurons_hid1]), dtype=tf.float32)\n","b1 = tf.Variable(tf.zeros(neurons_hid1))\n","w2 = tf.Variable(initializer([neurons_hid1, neurons_hid2]), dtype=tf.float32)\n","b2 = tf.Variable(tf.zeros(neurons_hid2))\n","w3 = tf.Variable(initializer([neurons_hid2, neurons_hid3]), dtype=tf.float32)\n","b3 = tf.Variable(tf.zeros(neurons_hid3))\n","w4 = tf.Variable(initializer([neurons_hid3, num_outputs]), dtype=tf.float32)\n","b4 = tf.Variable(tf.zeros(num_outputs))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"G9UECPgRJFpS"},"outputs":[],"source":["# creating placeholder for the network\n","X = tf.placeholder(tf.float32, shape=[None, num_inputs])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"daTuLaokJFpS"},"outputs":[],"source":["initializer = tf.variance_scaling_initializer()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDf66LcbJFpS"},"outputs":[],"source":["# DL architecture with 3 hidden layer, H1 as encoder, H2 as lower dim vector and H3 as decoder\n","hid_layer1 = tf.nn.relu(tf.matmul(X, w1) + b1)\n","hid_layer2 = tf.nn.relu(tf.matmul(hid_layer1, w2) + b2)\n","hid_layer3 = tf.nn.relu(tf.matmul(hid_layer2, w3) + b3)\n","output_layer = tf.matmul(hid_layer3, w4) + b4\n","\n","'''if Linear Autoencoder PCA architecture'''\n","#hidden = fully_connected(X, num_hidden, activation_fn=None)\n","#outputs = fully_connected(hidden, num_outputs, activation_fn=None)\n","\n","# defining MSE loss function\n","loss = tf.reduce_mean(tf.square(output_layer - X))\n","\n","# using adam optimizer to train the network\n","optimizer = tf.train.AdamOptimizer(learning_rate) #tf.train.RMSPropOptimizer\n","train = optimizer.minimize(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"z3ybpnVSJFpU"},"outputs":[],"source":["init = tf.global_variables_initializer()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L37i_0R7JFpU","outputId":"7fec777a-e394-41ca-f9e6-03eff514fca2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 Complete. Training Loss: 0.03161703050136566\n","Epoch 1 Complete. Training Loss: 0.026947470381855965\n","Epoch 2 Complete. Training Loss: 0.025991328060626984\n","Epoch 3 Complete. Training Loss: 0.026057124137878418\n","Epoch 4 Complete. Training Loss: 0.02522892877459526\n"]}],"source":["with tf.Session() as sess:\n","    sess.run(init)    \n","    for epoch in range(num_epochs):\n","        num_batches = X.shape[0] // batch_size        \n","        for iteration in range(num_batches):\n","            sess.run(train, feed_dict={X: scaled_data})\n","        training_loss = loss.eval(feed_dict={X: X_batch})   \n","        dim_red_features = hid_layer2.eval(feed_dict={X: scaled_data}) # Now ask for the hidden layer output (the 2 dimensional output)\n","        print(\"Epoch {} Complete. Training Loss: {}\".format(epoch,training_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZm7HT6pUu4g"},"outputs":[],"source":["dim_red_features.shape"]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":["Ncnt81reU87j"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"}},"nbformat":4,"nbformat_minor":0}
